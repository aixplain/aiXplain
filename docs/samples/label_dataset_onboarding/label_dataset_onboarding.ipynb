{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Label Detection Dataset Onboarding\n",
    "\n",
    "This notebook demonstrates how to onboard a dataset with label data into aiXplain platform using its SDK."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credentials\n",
    "\n",
    "To use the aiXplain SDK, you may be registered in our platform and have an API key. The step-by-step on how to do it is better described [here](/docs/user/api_setup.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TEAM_API_KEY\"] = \"YOUR_TEAM_API_KEY_HERE\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "In this example we will show how to onboard a sample dataset of images and their corresponding labels. To onboard it, the data needs to be depicted in a CSV file, which will be fed to the SDK. \n",
    "\n",
    "Label data should have be one or more elements in a JSON file according to one of the following structure:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"data\": \"TEXT_AUDIO_LABEL\",\n",
    "    \"boundingBox\": {\n",
    "        \"start\": 0, // start character\n",
    "        \"end\": 0, // end character\n",
    "    }\n",
    "}\n",
    "\n",
    "{\n",
    "    \"data\": \"AUDIO_LABEL\",\n",
    "    \"boundingBox\": {\n",
    "        \"start\": 0, // start second\n",
    "        \"end\": 0 // end second\n",
    "    }\n",
    "}\n",
    "\n",
    "{\n",
    "    \"data\": \"IMAGE_LABEL\",\n",
    "    \"boundingBox\": {\n",
    "        \"top\": 0, // top percentage of the image\n",
    "        \"bottom\": 0, // bottom percentage of the image\n",
    "        \"left\": 0, // left percentage of the image\n",
    "        \"right\": 0 // right percentage of the image\n",
    "    }\n",
    "}\n",
    "\n",
    "{\n",
    "    \"data\": \"VIDEO_LABEL\",\n",
    "    \"boundingBox\": {\n",
    "        \"start\": 0, // start second\n",
    "        \"end\": 0, // end second\n",
    "        \"top\": 0, // top percentage of the image\n",
    "        \"bottom\": 0, // bottom percentage of the image\n",
    "        \"left\": 0, // left percentage of the image\n",
    "        \"right\": 0 // right percentage of the image\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1p/jbswfpbs73q5qbbh78dzj5xm0000gn/T/ipykernel_47954/611755932.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>images</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>corpus/images/1.jpg</td>\n",
       "      <td>corpus/labels/1.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>corpus/images/2.png</td>\n",
       "      <td>corpus/labels/2.json</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0               images                labels\n",
       "0           0  corpus/images/1.jpg  corpus/labels/1.json\n",
       "1           1  corpus/images/2.png  corpus/labels/2.json"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "upload_file = \"corpus/index.csv\"\n",
    "data = pd.read_csv(upload_file)\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import\n",
    "\n",
    "Let's now import the necessary classes to onboard the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aixplain.enums import DataType, DataSubtype, Function, Language, License, StorageType\n",
    "from aixplain.factories import DatasetFactory\n",
    "from aixplain.modules import MetaData"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata\n",
    "\n",
    "Besides the CSV file, a schema must be fed to the SDK giving some information about the input and output data to be onboarded, such as: \n",
    "\n",
    "1. Data Name\n",
    "2. Data Type: Audio, Text, Image, Video, Label, etc.\n",
    "3. Storage Type: whether the data is depicted in the CSV (Text), in a local file (File) or in a public link (URL)\n",
    "4. Start Column (optional): the column which depicts the beginning of the segment in the original file\n",
    "5. End Column (optional): the column which depicts the end of the segment in the original file\n",
    "6. Languages (optional): the languages depicted in the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's instantiate the metadata for the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_meta = MetaData(\n",
    "    name=\"images\", \n",
    "    dtype=\"image\", \n",
    "    storage_type=\"file\", \n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the labels...\n",
    "\n",
    "(See how we can use enumerations instead of strings to specify some information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_meta = MetaData(\n",
    "    name=\"labels\", \n",
    "    dtype=DataType.LABEL, \n",
    "    storage_type=StorageType.FILE,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now create the schemas for the input and output data of the dataset. Since this is a image label detection dataset, the images will be set as the input and the labels as the output data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_schema = [image_meta]\n",
    "output_schema = [label_meta]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can called the `create` method to onboard the dataset, specifying the name, description, license, path to the content files and schemas. \n",
    "\n",
    "See that a Dataset ID will be provided as response together with the status of the onboarding process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Dataset's inputs onboard progress:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "\u001b[A\n",
      " Dataset's inputs onboard progress: 100%|██████████| 1/1 [00:06<00:00,  6.71s/it]\n",
      " Dataset's outputs onboard progress:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "\u001b[A\n",
      " Dataset's outputs onboard progress: 100%|██████████| 1/1 [00:02<00:00,  2.51s/it]\n",
      " Dataset's hypotheses onboard progress: 0it [00:00, ?it/s]\n",
      " Dataset's meta onboard progress: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'onboarding', 'asset_id': '6615453db2166233fe1ab291'}\n"
     ]
    }
   ],
   "source": [
    "payload = DatasetFactory.create(\n",
    "    name=\"dataset_onboarding_demo\",\n",
    "    description=\"This is an image label detection corpus\",\n",
    "    license=License.MIT,\n",
    "    function=Function.IMAGE_LABEL_DETECTION,\n",
    "    content_path=upload_file,\n",
    "    input_schema=input_schema,\n",
    "    output_schema=output_schema\n",
    ")\n",
    "print(payload)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then check the dataset using the `get` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Start service for GET Dataset  - https://dev-platform-api.aixplain.com/sdk/datasets/6615453db2166233fe1ab291/overview - {'Authorization': 'Token 9136c08bf02b5552885b9f2a5e0fae517d81ff2fa6fe7084a3adb655c4aa7215', 'Content-Type': 'application/json'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': '6615453db2166233fe1ab291',\n",
       " 'name': 'dataset_onboarding_demo',\n",
       " 'description': 'This is an image label detection corpus',\n",
       " 'supplier': 'aiXplain',\n",
       " 'version': '1.0',\n",
       " 'license': <License.MIT: '620ba3a83e2fa95c500b429d'>,\n",
       " 'privacy': <Privacy.PRIVATE: 'Private'>,\n",
       " 'cost': 0,\n",
       " 'onboard_status': <OnboardStatus.ONBOARDING: 'onboarding'>,\n",
       " 'function': <Function.IMAGE_LABEL_DETECTION: 'image-label-detection'>,\n",
       " 'source_data': {'images': <aixplain.modules.data.Data at 0x117d50810>},\n",
       " 'target_data': {'labels': [<aixplain.modules.data.Data at 0x117d3f690>]},\n",
       " 'hypotheses': {},\n",
       " 'metadata': {},\n",
       " 'tags': [],\n",
       " 'length': None,\n",
       " 'kwargs': {}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = DatasetFactory.get(payload[\"asset_id\"])\n",
    "dataset.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
