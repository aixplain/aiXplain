// Copyright 2023 aiXplain authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

syntax = "proto3";

import "google/protobuf/duration.proto";

option java_multiple_files = true;
option java_package = "com.aixplain.stream";
option java_outer_classname = "AixplainDiarizationStreamingProto";
option objc_class_prefix = "RTG";

package aixplaindiarizationstreaming;

// Interface exported by the server.
service AixplainDiarizationStreaming {
  // The ServerLive API indicates if the inference server is able to receive
  // and respond to metadata and inference requests.
  rpc ServerLive(ServerLiveRequest) returns (ServerLiveResponse) {}

  // The ServerReady API indicates if the server is ready for inferencing.
  rpc ServerReady(ServerReadyRequest) returns (ServerReadyResponse) {}

  // The ModelReady API indicates if a specific model is ready for inferencing.
  rpc ModelReady(ModelReadyRequest) returns (ModelReadyResponse) {}

  // The ServerMetadata API provides information about the server. Errors are
  // indicated by the google.rpc.Status returned for the request. The OK code
  // indicates success and other codes indicate failure.
  rpc ServerMetadata(ServerMetadataRequest) returns (ServerMetadataResponse) {}

  // The per-model metadata API provides information about a model. Errors are
  // indicated by the google.rpc.Status returned for the request. The OK code
  // indicates success and other codes indicate failure.
  rpc ModelMetadata(ModelMetadataRequest) returns (ModelMetadataResponse) {}

  // The Diarize API performs streaming inference using the specified audio config.
  // Errors are indicated by the google.rpc.Status returned for the request.
  // The OK code indicates success and other codes indicate failure.
  rpc Diarize(stream DiarizationRequest) returns (stream DiarizationResponse) {}
}

message ServerLiveRequest {}

message ServerLiveResponse
{
  // True if the inference server is live, false if not live.
  bool live = 1;
}

message ServerReadyRequest {}

message ServerReadyResponse
{
  // True if the inference server is ready, false if not ready.
  bool ready = 1;
}

message ModelReadyRequest
{
  // The name of the model to check for readiness.
  string name = 1;

  // The version of the model to check for readiness. If not given the
  // server will choose a version based on the model and internal policy.
  string version = 2;
}

message ModelReadyResponse
{
  // True if the model is ready, false if not ready.
  bool ready = 1;
}

message ServerMetadataRequest {}

message ServerMetadataResponse
{
  // The server name.
  string name = 1;

  // The server version.
  string version = 2;

  // The extensions supported by the server.
  repeated string extensions = 3;
}

message ModelMetadataRequest
{
  // The name of the model.
  string name = 1;

  // The version of the model to check for readiness. If not given the
  // server will choose a version based on the model and internal policy.
  string version = 2;
}

message ModelMetadataResponse
{

  // The model name.
  string name = 1;

  // The versions of the model available on the server.
  repeated string versions = 2;

  // The model's platform. See Platforms.
  string platform = 3;

}

message AudioConfig
{
    // Audio encoding format, one of: ("LINEAR16",)
    string encoding = 1;

    // Sample rate for the audio in hertz
    int32 hertz = 2;

    // Language code for the language spoken in the audio, one of ("en", )
    string language_code = 3;
}

message DiarizationConfig
{
    // Minimum number of speakers in the conversation.
    // This range gives you more flexibility by allowing the system to automatically determine the correct number of speakers.
    // If not set, the default value is 2.
    int32 min_speaker_count = 1;

    // Minimum number of speakers in the conversation.
    // This range gives you more flexibility by allowing the system to automatically determine the correct number of speakers.
    // If not set, the default value is 6.
    int32 max_speaker_count = 2;
}

message DiarizationRequest
{

  // The config for streaming
  AudioConfig config = 1;

  // Audio content encoded in bytes.
  bytes audio_content = 2;

  DiarizationConfig diarization_config = 3;

  // model latency, default = 0.5 s
  float latency = 4;
}

message SpeakerSegment
{
  // id of the person speaking
  string speaker_tag = 1;
  // time relative from the start when the person started speaking
  google.protobuf.Duration start_time = 2;
  // time relative from the start when the person stopped speaking
  google.protobuf.Duration end_time = 3;
  // model confidence
  float confidence = 4;
}

message DiarizationResponse
{
    // List of Speaker segments
    repeated SpeakerSegment segments = 1;

    // Represents if this is the final time the speech recognition service will return
    // this result for the given segment of audio.
    bool is_final = 2;

    // End time of the recognised spoken content relative to the beginning of the audio input
    google.protobuf.Duration end_time = 3;

    // Language code for the language spoken in the audio
    string language_code = 4;

}
